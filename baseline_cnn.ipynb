{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements needed\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import torchvision\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm \n",
    "import torchvision.models as models\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use GPU if applicable\n",
    "print(torch.cuda.is_available())\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"imagenette2/train\"\n",
    "test_path = \"imagenette2/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),  \n",
    "    transforms.ToTensor(),           \n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.ImageFolder(root=train_path, transform=transform)\n",
    "test = datasets.ImageFolder(root=test_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3925"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 0.1608,  0.3490,  0.0275,  ...,  0.5373,  0.4667,  0.3961],\n",
      "         [-0.2235, -0.1373,  0.0510,  ...,  0.5765,  0.5216,  0.4510],\n",
      "         [-0.3961, -0.4588,  0.0510,  ...,  0.5843,  0.5451,  0.5137],\n",
      "         ...,\n",
      "         [-0.1765, -0.2078, -0.2157,  ..., -0.1686, -0.2000, -0.1922],\n",
      "         [-0.2235, -0.2549, -0.2627,  ..., -0.2000, -0.2392, -0.2235],\n",
      "         [-0.2784, -0.2941, -0.3098,  ..., -0.2392, -0.2549, -0.2549]],\n",
      "\n",
      "        [[ 0.2706,  0.4118,  0.0902,  ...,  0.6000,  0.5451,  0.4745],\n",
      "         [-0.1529, -0.0588,  0.1529,  ...,  0.6549,  0.6157,  0.5529],\n",
      "         [-0.3647, -0.4039,  0.1137,  ...,  0.6706,  0.6471,  0.6078],\n",
      "         ...,\n",
      "         [ 0.1686,  0.1373,  0.1137,  ..., -0.1529, -0.1608, -0.1451],\n",
      "         [ 0.0667,  0.0510,  0.0353,  ..., -0.1686, -0.1843, -0.1765],\n",
      "         [-0.0118, -0.0196, -0.0275,  ..., -0.1843, -0.1922, -0.1922]],\n",
      "\n",
      "        [[-0.3176, -0.1765, -0.2314,  ...,  0.5451,  0.4824,  0.4118],\n",
      "         [-0.5451, -0.4824, -0.3882,  ...,  0.5765,  0.5294,  0.4667],\n",
      "         [-0.5529, -0.6392, -0.4353,  ...,  0.5843,  0.5529,  0.5216],\n",
      "         ...,\n",
      "         [ 0.2235,  0.1529,  0.1137,  ..., -0.4588, -0.5137, -0.4980],\n",
      "         [ 0.1373,  0.0667,  0.0275,  ..., -0.5059, -0.5294, -0.5059],\n",
      "         [ 0.0667, -0.0039, -0.0431,  ..., -0.5294, -0.5137, -0.4980]]]), 0)\n"
     ]
    }
   ],
   "source": [
    "for x in train:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_loop(loss_func, optimizer, epochs, train_dataloader, test_dataloader, model):\n",
    "    # variables needed for metrics later\n",
    "    train_losses = []\n",
    "    test_losses = 0\n",
    "    train_accuracy = []\n",
    "    test_accuracy = 0\n",
    "    start_time_train = time.time()\n",
    "    ############################ Train Loop ############################\n",
    "    for epoch in range(epochs):\n",
    "        # variables needed for metrics later\n",
    "        train_size = len(train_dataloader.dataset)\n",
    "        # makes sure to set model to train\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_num_batches = len(train_dataloader)\n",
    "        # Just to help with keep track of how long it taking\n",
    "        train_loadbar = tqdm(train_dataloader, total=train_num_batches)\n",
    "        for batch, (X, labels) in enumerate(train_loadbar):\n",
    "            # Make sure values are on correct device\n",
    "            X = X.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Model pred + loss\n",
    "            pred = model(X)\n",
    "            loss = loss_func(pred, labels)\n",
    "\n",
    "            # Backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Compute metrics\n",
    "            train_loss+=loss.item()\n",
    "            train_correct+=(pred.argmax(axis = 1) == labels).type(torch.float).sum().item()\n",
    "\n",
    "            # Update the loading bar    \n",
    "            train_loadbar.set_description(f'Epoch [{epoch + 1}/{epochs}]')\n",
    "            train_loadbar.set_postfix(train_loss=train_loss/(batch + 1), train_accuracy=train_correct/train_size)\n",
    "\n",
    "\n",
    "        # Compute metrics\n",
    "        train_losses.append(train_loss/train_num_batches)\n",
    "        train_accuracy.append(train_correct/train_size)\n",
    "\n",
    "        end_time_train = time.time()\n",
    "        train_time = end_time_train - start_time_train\n",
    "        ############################ Train Loop ############################\n",
    "        \n",
    "        ############################ Test Loop #############################\n",
    "        test_size = len(test_dataloader.dataset)\n",
    "        test_num_batches = len(test_dataloader)\n",
    "        # makes sure to set model to eval\n",
    "        model.eval()\n",
    "        # variables needed for metrics later\n",
    "        start_time_test = time.time()\n",
    "        test_loss = 0\n",
    "        test_correct = 0\n",
    "        test_loadbar = tqdm(test_dataloader, total=test_num_batches)\n",
    "        with torch.no_grad():\n",
    "            for batch, (X, labels) in enumerate(test_loadbar):\n",
    "                # Make sure values are on correct device\n",
    "                X = X.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Model pred + loss\n",
    "                pred = model(X)\n",
    "                loss = loss_func(pred, labels)\n",
    "\n",
    "                # Compute metrics\n",
    "                test_loss+=loss.item()\n",
    "                test_correct+=(pred.argmax(axis = 1) == labels).type(torch.float).sum().item()\n",
    "                test_loadbar.set_description(f'Epoch [{epoch + 1}/{epochs}]')\n",
    "                test_loadbar.set_postfix(test_loss=test_loss/(batch + 1))\n",
    "            # Compute metrics\n",
    "            test_losses = test_loss/test_num_batches\n",
    "            test_accuracy = test_correct/test_size\n",
    "        print(f\"Test Acc {test_accuracy}\")\n",
    "        \n",
    "        end_time_test = time.time()\n",
    "        test_time = end_time_test - start_time_test\n",
    "        ############################ Test Loop #############################\n",
    "\n",
    "    return train_accuracy, train_losses, test_accuracy, test_losses, train_time, test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Shaan/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "c:\\Users\\Shaan\\miniconda3\\envs\\proj\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Shaan\\miniconda3\\envs\\proj\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch [1/20]: 100%|██████████| 148/148 [02:39<00:00,  1.08s/it, train_accuracy=0.224, train_loss=2.96] \n",
      "Epoch [1/20]: 100%|██████████| 62/62 [00:40<00:00,  1.52it/s, test_loss=2.3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc 0.11847133757961784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/20]: 100%|██████████| 148/148 [02:02<00:00,  1.21it/s, train_accuracy=0.068, train_loss=2.35]  \n",
      "Epoch [2/20]: 100%|██████████| 62/62 [00:30<00:00,  2.00it/s, test_loss=2.3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc 0.056560509554140125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/20]:  15%|█▍        | 22/148 [00:17<01:37,  1.29it/s, train_accuracy=0, train_loss=2.32]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Shaan\\Documents\\Masters 3\\Big Data\\Project\\baseline_cnn.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Shaan/Documents/Masters%203/Big%20Data/Project/baseline_cnn.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m train_dataloader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(train, batch_size\u001b[39m=\u001b[39mbatch_size)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Shaan/Documents/Masters%203/Big%20Data/Project/baseline_cnn.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m test_dataloader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(test, batch_size\u001b[39m=\u001b[39mbatch_size)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Shaan/Documents/Masters%203/Big%20Data/Project/baseline_cnn.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m train_accuracy, train_losses, test_accuracy, test_losses, train_time, test_time \u001b[39m=\u001b[39m train_test_loop(loss_func, optimizer, epochs, train_dataloader, test_dataloader, model)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Shaan/Documents/Masters%203/Big%20Data/Project/baseline_cnn.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Print results to table\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Shaan/Documents/Masters%203/Big%20Data/Project/baseline_cnn.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m data \u001b[39m=\u001b[39m [train_time, test_time, train_accuracy[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], test_accuracy, \u001b[39m64\u001b[39m, \u001b[39m.0001\u001b[39m]\n",
      "\u001b[1;32mc:\\Users\\Shaan\\Documents\\Masters 3\\Big Data\\Project\\baseline_cnn.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Shaan/Documents/Masters%203/Big%20Data/Project/baseline_cnn.ipynb#W6sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Shaan/Documents/Masters%203/Big%20Data/Project/baseline_cnn.ipynb#W6sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# Compute metrics\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Shaan/Documents/Masters%203/Big%20Data/Project/baseline_cnn.ipynb#W6sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m train_loss\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mloss\u001b[39m.\u001b[39;49mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Shaan/Documents/Masters%203/Big%20Data/Project/baseline_cnn.ipynb#W6sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m train_correct\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m(pred\u001b[39m.\u001b[39margmax(axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m labels)\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mfloat)\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Shaan/Documents/Masters%203/Big%20Data/Project/baseline_cnn.ipynb#W6sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Update the loading bar    \u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compact high-level loop that runs everything and allows modification of all variables\n",
    "#model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_1', pretrained = True)\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "# Make 10 class classifier\n",
    "#model.classifier[1] = nn.Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1))\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "model.to(device)\n",
    "############################################# HYPER PARAMS #############################################\n",
    "batch_size = 64\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "lr = .0001\n",
    "weight_decay = .0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "epochs = 20\n",
    "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=epochs/3, gamma=.5)\n",
    "############################################# HYPER PARAMS #############################################\n",
    "train_dataloader = torch.utils.data.DataLoader(train, batch_size=batch_size)\n",
    "test_dataloader = torch.utils.data.DataLoader(test, batch_size=batch_size)\n",
    "train_accuracy, train_losses, test_accuracy, test_losses, train_time, test_time = train_test_loop(loss_func, optimizer, epochs, train_dataloader, test_dataloader, model)\n",
    "# Print results to table\n",
    "data = [train_time, test_time, train_accuracy[-1], test_accuracy, 64, .0001]\n",
    "#torch.save(model.state_dict(), f'models/Default_Model.pth')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[541.7273671627045, 117.98300266265869, 0.8051366283410483, 0.29304166044497537, 64, 0.0001]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
